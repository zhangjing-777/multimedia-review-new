"""
é‡æ–°è®¾è®¡çš„æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡
æ·»åŠ åˆ†å¸ƒå¼é”æœºåˆ¶é˜²æ­¢é‡å¤å¤„ç†
"""

import redis
import json
from typing import Dict, Any, Optional
from datetime import datetime
from loguru import logger
from contextlib import contextmanager
from app.workers.review_worker import process_review_task, process_review_file
from celery import current_app

from app.config import get_settings


class QueueService:
    """å¸¦é”æœºåˆ¶çš„æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡ç±»"""
    
    def __init__(self):
        self.settings = get_settings()
        
        # Redis è¿æ¥
        self.redis = redis.Redis.from_url(
            self.settings.CELERY_BROKER_URL,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=5
        )
        
        # ç¼“å­˜ Redis è¿æ¥
        self.cache_redis = redis.Redis.from_url(
            self.settings.REDIS_CACHE_URL,
            decode_responses=True
        )
        
        logger.info(f"QueueService åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ Celery Broker: {self.settings.CELERY_BROKER_URL}")
    
    @contextmanager
    def task_lock(self, task_id: str, timeout: int = 3600):
        """
        ä»»åŠ¡åˆ†å¸ƒå¼é”ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            task_id: ä»»åŠ¡ID
            timeout: é”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        lock_key = f"task_lock:{task_id}"
        lock_value = f"worker_{datetime.utcnow().timestamp()}"
        
        # å°è¯•è·å–é”
        acquired = self.cache_redis.set(lock_key, lock_value, nx=True, ex=timeout)
        
        if not acquired:
            raise RuntimeError(f"ä»»åŠ¡ {task_id} æ­£åœ¨è¢«å…¶ä»–è¿›ç¨‹å¤„ç†")
        
        try:
            logger.info(f"ğŸ”’ è·å–ä»»åŠ¡é”: {task_id}")
            yield
        finally:
            # é‡Šæ”¾é”ï¼ˆåªæœ‰é”çš„æŒæœ‰è€…æ‰èƒ½é‡Šæ”¾ï¼‰
            lua_script = """
            if redis.call("get", KEYS[1]) == ARGV[1] then
                return redis.call("del", KEYS[1])
            else
                return 0
            end
            """
            self.cache_redis.eval(lua_script, 1, lock_key, lock_value)
            logger.info(f"ğŸ”“ é‡Šæ”¾ä»»åŠ¡é”: {task_id}")
    
    @contextmanager 
    def file_lock(self, file_id: str, timeout: int = 1800):
        """
        æ–‡ä»¶åˆ†å¸ƒå¼é”ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            file_id: æ–‡ä»¶ID
            timeout: é”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        lock_key = f"file_lock:{file_id}"
        lock_value = f"worker_{datetime.utcnow().timestamp()}"
        
        acquired = self.cache_redis.set(lock_key, lock_value, nx=True, ex=timeout)
        
        if not acquired:
            raise RuntimeError(f"æ–‡ä»¶ {file_id} æ­£åœ¨è¢«å…¶ä»–è¿›ç¨‹å¤„ç†")
        
        try:
            logger.info(f"ğŸ”’ è·å–æ–‡ä»¶é”: {file_id}")
            yield
        finally:
            lua_script = """
            if redis.call("get", KEYS[1]) == ARGV[1] then
                return redis.call("del", KEYS[1])
            else
                return 0
            end
            """
            self.cache_redis.eval(lua_script, 1, lock_key, lock_value)
            logger.info(f"ğŸ”“ é‡Šæ”¾æ–‡ä»¶é”: {file_id}")
    
    def add_task_to_queue(self, task_id: str, priority: int = 0) -> bool:
        """
        å°†ä»»åŠ¡æ·»åŠ åˆ° Celery é˜Ÿåˆ—ï¼ˆæ£€æŸ¥é‡å¤ï¼‰
        """
        try:
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»åœ¨å¤„ç†ä¸­
            if self.is_task_processing(task_id):
                logger.warning(f"ä»»åŠ¡ {task_id} å·²åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡é‡å¤æäº¤")
                return False
            
            logger.info(f"ğŸš€ æäº¤ä»»åŠ¡åˆ° Celery: {task_id}")
            result = process_review_task.delay(task_id)
            
            # æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
            self.set_task_status(task_id, "submitted", {
                "celery_task_id": result.id,
                "priority": priority,
                "processing": True
            })
            
            logger.info(f"âœ… ä»»åŠ¡å·²æäº¤ï¼ŒCeleryä»»åŠ¡ID: {result.id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def add_file_to_queue(self, file_id: str, task_id: str, file_type: str, priority: int = 0) -> bool:
        """
        å°†æ–‡ä»¶æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—ï¼ˆæ£€æŸ¥é‡å¤ï¼‰
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨å¤„ç†ä¸­
            if self.is_file_processing(file_id):
                logger.warning(f"æ–‡ä»¶ {file_id} å·²åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡é‡å¤æäº¤")
                return False
            
            logger.info(f"ğŸš€ æäº¤æ–‡ä»¶å¤„ç†ä»»åŠ¡: {file_id}")
            result = process_review_file.delay(file_id, task_id, file_type)
            
            # æ ‡è®°æ–‡ä»¶ä¸ºå¤„ç†ä¸­
            self.set_file_status(file_id, "submitted", {
                "celery_task_id": result.id,
                "task_id": task_id,
                "file_type": file_type,
                "processing": True
            })
            
            logger.info(f"âœ… æ–‡ä»¶ä»»åŠ¡å·²æäº¤ï¼ŒCeleryä»»åŠ¡ID: {result.id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æäº¤æ–‡ä»¶ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def is_task_processing(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­"""
        lock_key = f"task_lock:{task_id}"
        return self.cache_redis.exists(lock_key) > 0
    
    def is_file_processing(self, file_id: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­"""
        lock_key = f"file_lock:{file_id}"
        return self.cache_redis.exists(lock_key) > 0
    
    def get_task_status(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        try:
            key = f"task_status:{task_id}"
            status_json = self.cache_redis.get(key)
            
            if status_json:
                return json.loads(status_json)
            return None
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def set_task_status(self, task_id: str, status: str, extra_data: Dict = None) -> bool:
        """è®¾ç½®ä»»åŠ¡çŠ¶æ€"""
        try:
            status_data = {
                "status": status,
                "updated_at": datetime.utcnow().isoformat()
            }
            
            if extra_data:
                status_data.update(extra_data)
            
            key = f"task_status:{task_id}"
            self.cache_redis.setex(key, 86400, json.dumps(status_data))
            return True
            
        except Exception as e:
            logger.error(f"è®¾ç½®ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def get_file_status(self, file_id: str) -> Optional[Dict]:
        """è·å–æ–‡ä»¶çŠ¶æ€"""
        try:
            key = f"file_status:{file_id}"
            status_json = self.cache_redis.get(key)
            
            if status_json:
                return json.loads(status_json)
            return None
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def set_file_status(self, file_id: str, status: str, extra_data: Dict = None) -> bool:
        """è®¾ç½®æ–‡ä»¶çŠ¶æ€"""
        try:
            status_data = {
                "status": status,
                "updated_at": datetime.utcnow().isoformat()
            }
            
            if extra_data:
                status_data.update(extra_data)
            
            key = f"file_status:{file_id}"
            self.cache_redis.setex(key, 86400, json.dumps(status_data))
            return True
            
        except Exception as e:
            logger.error(f"è®¾ç½®æ–‡ä»¶çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def update_progress(self, entity_id: str, progress: int, message: str = "") -> bool:
        """æ›´æ–°å¤„ç†è¿›åº¦"""
        try:
            progress_data = {
                "progress": max(0, min(100, progress)),
                "message": message,
                "updated_at": datetime.utcnow().isoformat()
            }
            
            key = f"progress:{entity_id}"
            self.cache_redis.setex(key, 3600, json.dumps(progress_data))
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
            return False
    
    def get_progress(self, entity_id: str) -> Optional[Dict]:
        """è·å–å¤„ç†è¿›åº¦"""
        try:
            key = f"progress:{entity_id}"
            progress_json = self.cache_redis.get(key)
            
            if progress_json:
                return json.loads(progress_json)
            return None
            
        except Exception as e:
            logger.error(f"è·å–è¿›åº¦å¤±è´¥: {e}")
            return None
    
    def get_queue_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€ç»Ÿè®¡"""
        try:
            
            inspect = current_app.control.inspect()
            active_tasks = inspect.active()
            reserved_tasks = inspect.reserved()
            
            total_active = sum(len(tasks) for tasks in (active_tasks or {}).values())
            total_reserved = sum(len(tasks) for tasks in (reserved_tasks or {}).values())
            
            # ç»Ÿè®¡é”ä¿¡æ¯
            task_locks = len(self.cache_redis.keys("task_lock:*"))
            file_locks = len(self.cache_redis.keys("file_lock:*"))
            
            return {
                "active_tasks": total_active,
                "reserved_tasks": total_reserved,
                "total_pending": total_active + total_reserved,
                "workers_online": len(active_tasks or {}),
                "task_locks": task_locks,
                "file_locks": file_locks,
                "queue_info": "ä½¿ç”¨ Celery + Redis åˆ†å¸ƒå¼é”"
            }
            
        except Exception as e:
            logger.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
            return {
                "active_tasks": 0,
                "reserved_tasks": 0,
                "total_pending": 0,
                "workers_online": 0,
                "task_locks": 0,
                "file_locks": 0,
                "error": str(e)
            }
    
    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        try:
            # è·å– Celery ä»»åŠ¡ID
            task_status = self.get_task_status(task_id)
            if not task_status or "celery_task_id" not in task_status:
                return False
            
            # å–æ¶ˆ Celery ä»»åŠ¡
            current_app.control.revoke(task_status["celery_task_id"], terminate=True)
            
            # é‡Šæ”¾é”
            lock_key = f"task_lock:{task_id}"
            self.cache_redis.delete(lock_key)
            
            # æ›´æ–°çŠ¶æ€
            self.set_task_status(task_id, "cancelled")
            
            logger.info(f"âœ… ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
            return True
            
        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            self.redis.ping()
            self.cache_redis.ping()
            logger.info("âœ… QueueService è¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ QueueService è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False