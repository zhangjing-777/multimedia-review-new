
"""
æŠ¥å‘Šç”ŸæˆAPIè·¯ç”±
æä¾›æ™ºèƒ½æŠ¥å‘Šç”ŸæˆåŠŸèƒ½ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€å’Œæ—¶é—´é€‰æ‹©
"""

from datetime import datetime, timedelta
from typing import Optional, Dict, List
from fastapi import APIRouter, Depends, Query, Body
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_
import json
from io import StringIO
import csv
from fastapi.responses import Response
from loguru import logger

from app.database import get_db
from app.models.task import ReviewTask, TaskStatus
from app.models.file import ReviewFile, FileType, FileStatus
from app.models.result import ReviewResult, ViolationResult, SourceType
from app.utils.response import APIResponse

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter()

# è¯·æ±‚æ¨¡å‹
class ReportRequest(BaseModel):
    """æŠ¥å‘Šç”Ÿæˆè¯·æ±‚æ¨¡å‹"""
    report_type: str = Field(..., description="æŠ¥å‘Šç±»å‹: weekly/monthly/quarterly/yearly/custom")
    start_date: Optional[str] = Field(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD")
    end_date: Optional[str] = Field(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DD")
    description: Optional[str] = Field(None, description="è‡ªç„¶è¯­è¨€æè¿°ï¼Œå¦‚ï¼šæœ¬å‘¨ã€ä¸Šä¸ªæœˆã€ç¬¬ä¸‰å­£åº¦ç­‰")
    creator_id: Optional[str] = Field(None, description="åˆ›å»ºè€…è¿‡æ»¤")
    format: str = Field("json", regex="^(json|csv|markdown)$", description="è¾“å‡ºæ ¼å¼")
    detailed: bool = Field(True, description="æ˜¯å¦åŒ…å«è¯¦ç»†ç»Ÿè®¡")

@router.post("/generate", summary="ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š")
async def generate_report(
    request: ReportRequest,
    db: Session = Depends(get_db)
):
    """
    ç”Ÿæˆæ™ºèƒ½å®¡æ ¸æŠ¥å‘Š
    
    æ”¯æŒå¤šç§æŠ¥å‘Šç±»å‹ï¼š
    - **weekly**: å‘¨æŠ¥
    - **monthly**: æœˆæŠ¥  
    - **quarterly**: å­£æŠ¥
    - **yearly**: å¹´æŠ¥
    - **custom**: è‡ªå®šä¹‰æ—¶é—´èŒƒå›´
    
    æ”¯æŒè‡ªç„¶è¯­è¨€æè¿°ï¼š
    - "æœ¬å‘¨"ã€"ä¸Šå‘¨"ã€"è¿™ä¸ªæœˆ"ã€"ä¸Šä¸ªæœˆ"
    - "ç¬¬ä¸€å­£åº¦"ã€"ç¬¬äºŒå­£åº¦"ã€"ä»Šå¹´"ã€"å»å¹´"
    - "æœ€è¿‘7å¤©"ã€"æœ€è¿‘30å¤©"
    """
    try:
        # è§£ææ—¶é—´èŒƒå›´
        start_date, end_date = _parse_time_range(request)
        
        logger.info(f"ç”ŸæˆæŠ¥å‘Š: {request.report_type}, æ—¶é—´èŒƒå›´: {start_date} - {end_date}")
        
        # ç”ŸæˆæŠ¥å‘Šæ•°æ®
        report_data = _generate_report_data(db, start_date, end_date, request.creator_id, request.detailed)
        
        # æ·»åŠ æŠ¥å‘Šå…ƒä¿¡æ¯
        report_data["meta"] = {
            "report_type": request.report_type,
            "time_range": {
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat(),
                "description": request.description or f"{request.report_type} æŠ¥å‘Š"
            },
            "generated_at": datetime.utcnow().isoformat(),
            "creator_id": request.creator_id
        }
        
        # æ ¹æ®æ ¼å¼è¿”å›
        if request.format == "csv":
            return _export_report_csv(report_data)
        elif request.format == "markdown":
            return _export_report_markdown(report_data)
        else:
            return APIResponse.success(
                data=report_data,
                message="æŠ¥å‘Šç”ŸæˆæˆåŠŸ"
            )
    
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return APIResponse.error(
            message=f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
            code=500
        )

def _parse_time_range(request: ReportRequest) -> tuple:
    """è§£ææ—¶é—´èŒƒå›´"""
    now = datetime.utcnow()
    
    # å¦‚æœæŒ‡å®šäº†å…·ä½“æ—¥æœŸ
    if request.start_date and request.end_date:
        start_date = datetime.strptime(request.start_date, "%Y-%m-%d")
        end_date = datetime.strptime(request.end_date, "%Y-%m-%d").replace(hour=23, minute=59, second=59)
        return start_date, end_date
    
    # æ ¹æ®æŠ¥å‘Šç±»å‹è‡ªåŠ¨è®¡ç®—
    if request.report_type == "weekly":
        # æœ¬å‘¨ï¼šå‘¨ä¸€åˆ°å‘¨æ—¥
        days_since_monday = now.weekday()
        start_date = now - timedelta(days=days_since_monday)
        end_date = start_date + timedelta(days=6)
    
    elif request.report_type == "monthly":
        # æœ¬æœˆï¼š1å·åˆ°æœˆæœ«
        start_date = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        if now.month == 12:
            end_date = now.replace(year=now.year+1, month=1, day=1) - timedelta(seconds=1)
        else:
            end_date = now.replace(month=now.month+1, day=1) - timedelta(seconds=1)
    
    elif request.report_type == "quarterly":
        # å½“å‰å­£åº¦
        quarter = (now.month - 1) // 3 + 1
        start_month = (quarter - 1) * 3 + 1
        start_date = now.replace(month=start_month, day=1, hour=0, minute=0, second=0, microsecond=0)
        
        if quarter == 4:
            end_date = now.replace(year=now.year+1, month=1, day=1) - timedelta(seconds=1)
        else:
            end_month = start_month + 3
            end_date = now.replace(month=end_month, day=1) - timedelta(seconds=1)
    
    elif request.report_type == "yearly":
        # ä»Šå¹´ï¼š1æœˆ1æ—¥åˆ°12æœˆ31æ—¥
        start_date = now.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)
        end_date = now.replace(month=12, day=31, hour=23, minute=59, second=59)
    
    else:  # custom
        # é»˜è®¤æœ€è¿‘30å¤©
        start_date = now - timedelta(days=30)
        end_date = now
    
    return start_date, end_date

def _generate_report_data(db: Session, start_date: datetime, end_date: datetime, creator_id: Optional[str], detailed: bool) -> Dict:
    """ç”ŸæˆæŠ¥å‘Šæ•°æ®"""
    
    # åŸºç¡€æŸ¥è¯¢æ¡ä»¶
    date_filter = and_(
        ReviewTask.created_at >= start_date,
        ReviewTask.created_at <= end_date
    )
    
    if creator_id:
        date_filter = and_(date_filter, ReviewTask.creator_id == creator_id)
    
    # 1. ä»»åŠ¡ç»Ÿè®¡
    task_stats = _get_task_statistics(db, date_filter)
    
    # 2. æ–‡ä»¶ç»Ÿè®¡  
    file_stats = _get_file_statistics(db, date_filter, detailed)
    
    # 3. è¿è§„ç»Ÿè®¡
    violation_stats = _get_violation_statistics(db, date_filter, detailed)
    
    # 4. è¶‹åŠ¿åˆ†æï¼ˆå¦‚æœæ˜¯è¯¦ç»†æŠ¥å‘Šï¼‰
    trend_stats = {}
    if detailed:
        trend_stats = _get_trend_analysis(db, start_date, end_date, creator_id)
    
    # 5. æ±‡æ€»æ•°æ®
    summary = _calculate_summary(task_stats, file_stats, violation_stats)
    
    return {
        "summary": summary,
        "tasks": task_stats,
        "files": file_stats,
        "violations": violation_stats,
        "trends": trend_stats if detailed else None
    }

def _get_task_statistics(db: Session, date_filter) -> Dict:
    """è·å–ä»»åŠ¡ç»Ÿè®¡"""
    
    # æ€»ä»»åŠ¡æ•°
    total_tasks = db.query(ReviewTask).filter(date_filter).count()
    
    # æŒ‰çŠ¶æ€ç»Ÿè®¡
    status_stats = db.query(
        ReviewTask.status,
        func.count(ReviewTask.id).label('count')
    ).filter(date_filter).group_by(ReviewTask.status).all()
    
    # è¿è¡Œä¸­ä»»åŠ¡ï¼ˆprocessingï¼‰
    running_tasks = sum([stat.count for stat in status_stats if stat.status == TaskStatus.PROCESSING])
    
    # éè¿è¡Œä¸­ä»»åŠ¡
    non_running_tasks = total_tasks - running_tasks
    
    # æŒ‰ç­–ç•¥ç±»å‹ç»Ÿè®¡
    strategy_stats = db.query(
        ReviewTask.strategy_type,
        func.count(ReviewTask.id).label('count')
    ).filter(date_filter).group_by(ReviewTask.strategy_type).all()
    
    return {
        "total": total_tasks,
        "running": running_tasks,
        "non_running": non_running_tasks,
        "by_status": {
            stat.status.value: stat.count for stat in status_stats
        },
        "by_strategy": {
            (stat.strategy_type or "æœªåˆ†ç±»"): stat.count for stat in strategy_stats
        }
    }

def _get_file_statistics(db: Session, date_filter, detailed: bool) -> Dict:
    """è·å–æ–‡ä»¶ç»Ÿè®¡"""
    
    # åŸºç¡€æ–‡ä»¶ç»Ÿè®¡
    file_query = db.query(ReviewFile).join(ReviewTask).filter(date_filter)
    
    total_files = file_query.count()
    
    # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
    type_stats = db.query(
        ReviewFile.file_type,
        func.count(ReviewFile.id).label('count'),
        func.sum(ReviewFile.file_size).label('total_size')
    ).join(ReviewTask).filter(date_filter).group_by(ReviewFile.file_type).all()
    
    # æŒ‰çŠ¶æ€ç»Ÿè®¡
    status_stats = db.query(
        ReviewFile.status,
        func.count(ReviewFile.id).label('count')
    ).join(ReviewTask).filter(date_filter).group_by(ReviewFile.status).all()
    
    result = {
        "total": total_files,
        "by_type": {
            stat.file_type.value: {
                "count": stat.count,
                "total_size_mb": round((stat.total_size or 0) / (1024*1024), 2)
            } for stat in type_stats
        },
        "by_status": {
            stat.status.value: stat.count for stat in status_stats
        }
    }
    
    # è¯¦ç»†ç»Ÿè®¡ï¼šæ¯ç§æ–‡ä»¶ç±»å‹çš„è¿è§„æƒ…å†µ
    if detailed:
        result["detailed_by_type"] = {}
        for file_type in FileType:
            type_violation_stats = _get_file_type_violations(db, date_filter, file_type)
            if type_violation_stats["total"] > 0:
                result["detailed_by_type"][file_type.value] = type_violation_stats
    
    return result

def _get_file_type_violations(db: Session, date_filter, file_type: FileType) -> Dict:
    """è·å–ç‰¹å®šæ–‡ä»¶ç±»å‹çš„è¿è§„ç»Ÿè®¡"""
    
    # è¯¥ç±»å‹æ–‡ä»¶æ€»æ•°
    total_files = db.query(ReviewFile).join(ReviewTask).filter(
        date_filter, ReviewFile.file_type == file_type
    ).count()
    
    if total_files == 0:
        return {"total": 0, "violations": {}}
    
    # è¯¥ç±»å‹æ–‡ä»¶çš„è¿è§„ç»Ÿè®¡
    violation_stats = db.query(
        ReviewResult.violation_result,
        func.count(func.distinct(ReviewResult.file_id)).label('file_count'),
        func.count(ReviewResult.id).label('detection_count')
    ).join(ReviewFile).join(ReviewTask).filter(
        date_filter, ReviewFile.file_type == file_type
    ).group_by(ReviewResult.violation_result).all()
    
    # æœ‰è¿è§„çš„æ–‡ä»¶æ•°
    non_compliant_files = sum([
        stat.file_count for stat in violation_stats 
        if stat.violation_result == ViolationResult.NON_COMPLIANT
    ])
    
    # åˆè§„æ–‡ä»¶æ•°ï¼ˆæ€»æ•° - æœ‰æ£€æµ‹ç»“æœçš„æ–‡ä»¶æ•°ï¼Œå‡è®¾æ²¡æ£€æµ‹ç»“æœçš„æ˜¯åˆè§„çš„ï¼‰
    files_with_results = db.query(func.distinct(ReviewResult.file_id)).join(ReviewFile).join(ReviewTask).filter(
        date_filter, ReviewFile.file_type == file_type
    ).count()
    
    compliant_files = total_files - non_compliant_files
    
    return {
        "total": total_files,
        "compliant": compliant_files,
        "non_compliant": non_compliant_files,
        "violations": {
            stat.violation_result.value: {
                "file_count": stat.file_count,
                "detection_count": stat.detection_count
            } for stat in violation_stats
        }
    }

def _get_violation_statistics(db: Session, date_filter, detailed: bool) -> Dict:
    """è·å–è¿è§„ç»Ÿè®¡"""
    
    # æ€»æ£€æµ‹ç»“æœæ•°
    total_detections = db.query(ReviewResult).join(ReviewFile).join(ReviewTask).filter(date_filter).count()
    
    # æŒ‰è¿è§„ç»“æœç»Ÿè®¡
    result_stats = db.query(
        ReviewResult.violation_result,
        func.count(ReviewResult.id).label('count'),
        func.avg(ReviewResult.confidence_score).label('avg_confidence')
    ).join(ReviewFile).join(ReviewTask).filter(date_filter).group_by(ReviewResult.violation_result).all()
    
    # æŒ‰æ¥æºç±»å‹ç»Ÿè®¡
    source_stats = db.query(
        ReviewResult.source_type,
        func.count(ReviewResult.id).label('count')
    ).join(ReviewFile).join(ReviewTask).filter(date_filter).group_by(ReviewResult.source_type).all()
    
    # äººå·¥å¤å®¡ç»Ÿè®¡
    review_stats = db.query(
        ReviewResult.is_reviewed,
        func.count(ReviewResult.id).label('count')
    ).join(ReviewFile).join(ReviewTask).filter(date_filter).group_by(ReviewResult.is_reviewed).all()
    
    result = {
        "total_detections": total_detections,
        "by_result": {
            stat.violation_result.value: {
                "count": stat.count,
                "avg_confidence": round(float(stat.avg_confidence or 0), 3)
            } for stat in result_stats
        },
        "by_source": {
            stat.source_type.value: stat.count for stat in source_stats
        },
        "review_status": {
            "reviewed": sum([stat.count for stat in review_stats if stat.is_reviewed]),
            "unreviewed": sum([stat.count for stat in review_stats if not stat.is_reviewed])
        }
    }
    
    # è¯¦ç»†ç»Ÿè®¡
    if detailed:
        # é«˜ç½®ä¿¡åº¦è¿è§„
        high_confidence_violations = db.query(ReviewResult).join(ReviewFile).join(ReviewTask).filter(
            date_filter,
            ReviewResult.violation_result == ViolationResult.NON_COMPLIANT,
            ReviewResult.confidence_score >= 0.8
        ).count()
        
        # éœ€è¦äººå·¥å¤å®¡çš„æ•°é‡
        need_review = db.query(ReviewResult).join(ReviewFile).join(ReviewTask).filter(
            date_filter,
            ReviewResult.is_reviewed == False,
            or_(
                ReviewResult.violation_result == ViolationResult.UNCERTAIN,
                and_(
                    ReviewResult.violation_result == ViolationResult.NON_COMPLIANT,
                    ReviewResult.confidence_score < 0.6
                )
            )
        ).count()
        
        result["detailed"] = {
            "high_confidence_violations": high_confidence_violations,
            "need_manual_review": need_review
        }
    
    return result

def _get_trend_analysis(db: Session, start_date: datetime, end_date: datetime, creator_id: Optional[str]) -> Dict:
    """è·å–è¶‹åŠ¿åˆ†æ"""
    
    # æŒ‰å¤©ç»Ÿè®¡ä»»åŠ¡åˆ›å»ºæ•°é‡
    daily_tasks = db.query(
        func.date(ReviewTask.created_at).label('date'),
        func.count(ReviewTask.id).label('count')
    ).filter(
        ReviewTask.created_at >= start_date,
        ReviewTask.created_at <= end_date
    )
    
    if creator_id:
        daily_tasks = daily_tasks.filter(ReviewTask.creator_id == creator_id)
    
    daily_tasks = daily_tasks.group_by(func.date(ReviewTask.created_at)).all()
    
    # æŒ‰å¤©ç»Ÿè®¡è¿è§„æ£€æµ‹æ•°é‡
    daily_violations = db.query(
        func.date(ReviewResult.created_at).label('date'),
        func.count(ReviewResult.id).label('count')
    ).join(ReviewFile).join(ReviewTask).filter(
        ReviewTask.created_at >= start_date,
        ReviewTask.created_at <= end_date,
        ReviewResult.violation_result == ViolationResult.NON_COMPLIANT
    )
    
    if creator_id:
        daily_violations = daily_violations.filter(ReviewTask.creator_id == creator_id)
    
    daily_violations = daily_violations.group_by(func.date(ReviewResult.created_at)).all()
    
    return {
        "daily_tasks": [
            {"date": str(stat.date), "count": stat.count} for stat in daily_tasks
        ],
        "daily_violations": [
            {"date": str(stat.date), "count": stat.count} for stat in daily_violations
        ]
    }

def _calculate_summary(task_stats: Dict, file_stats: Dict, violation_stats: Dict) -> Dict:
    """è®¡ç®—æ±‡æ€»æ•°æ®"""
    
    # è®¡ç®—å„ç±»å‹æ–‡ä»¶çš„åˆè§„ç‡
    compliance_rate_by_type = {}
    if "detailed_by_type" in file_stats:
        for file_type, stats in file_stats["detailed_by_type"].items():
            if stats["total"] > 0:
                compliance_rate = (stats["compliant"] / stats["total"]) * 100
                compliance_rate_by_type[file_type] = round(compliance_rate, 2)
    
    # æ€»ä½“åˆè§„ç‡
    total_files = file_stats["total"]
    total_violations = violation_stats["by_result"].get("ä¸åˆè§„", {}).get("count", 0)
    
    # ç®€åŒ–è®¡ç®—ï¼šå‡è®¾æœ‰è¿è§„æ£€æµ‹çš„æ–‡ä»¶éƒ½æ˜¯ä¸åˆè§„çš„
    # æ›´ç²¾ç¡®çš„è®¡ç®—éœ€è¦ç»Ÿè®¡unique file_id
    estimated_compliant_files = max(0, total_files - total_violations)
    overall_compliance_rate = (estimated_compliant_files / total_files * 100) if total_files > 0 else 100
    
    return {
        "time_period_summary": f"å…±å¤„ç† {task_stats['total']} ä¸ªä»»åŠ¡ï¼Œ{file_stats['total']} ä¸ªæ–‡ä»¶",
        "task_completion_rate": round((task_stats.get('non_running', 0) / task_stats['total'] * 100), 2) if task_stats['total'] > 0 else 0,
        "overall_compliance_rate": round(overall_compliance_rate, 2),
        "compliance_by_type": compliance_rate_by_type,
        "top_violation_source": max(violation_stats["by_source"].items(), key=lambda x: x[1])[0] if violation_stats["by_source"] else "æ— ",
        "review_completion_rate": round((violation_stats["review_status"]["reviewed"] / violation_stats["total_detections"] * 100), 2) if violation_stats["total_detections"] > 0 else 0
    }

def _export_report_csv(report_data: Dict) -> Response:
    """å¯¼å‡ºCSVæ ¼å¼æŠ¥å‘Š"""
    output = StringIO()
    writer = csv.writer(output)
    
    # å†™å…¥æŠ¥å‘Šå…ƒä¿¡æ¯
    writer.writerow(["å®¡æ ¸æŠ¥å‘Š", report_data["meta"]["time_range"]["description"]])
    writer.writerow(["ç”Ÿæˆæ—¶é—´", report_data["meta"]["generated_at"]])
    writer.writerow([])
    
    # æ±‡æ€»ä¿¡æ¯
    writer.writerow(["æ±‡æ€»ä¿¡æ¯"])
    for key, value in report_data["summary"].items():
        writer.writerow([key, value])
    writer.writerow([])
    
    # ä»»åŠ¡ç»Ÿè®¡
    writer.writerow(["ä»»åŠ¡ç»Ÿè®¡"])
    writer.writerow(["æ€»ä»»åŠ¡æ•°", report_data["tasks"]["total"]])
    writer.writerow(["è¿è¡Œä¸­", report_data["tasks"]["running"]])
    writer.writerow(["éè¿è¡Œä¸­", report_data["tasks"]["non_running"]])
    writer.writerow([])
    
    # æ–‡ä»¶ç»Ÿè®¡
    writer.writerow(["æ–‡ä»¶ç»Ÿè®¡"])
    writer.writerow(["æ–‡ä»¶ç±»å‹", "æ•°é‡", "æ€»å¤§å°(MB)"])
    for file_type, stats in report_data["files"]["by_type"].items():
        writer.writerow([file_type, stats["count"], stats["total_size_mb"]])
    
    content = output.getvalue()
    output.close()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"å®¡æ ¸æŠ¥å‘Š_{timestamp}.csv"
    
    return Response(
        content=content.encode('utf-8-sig'),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

def _export_report_markdown(report_data: Dict) -> Response:
    """å¯¼å‡ºMarkdownæ ¼å¼æŠ¥å‘Š"""
    md_content = f"""# å¤šåª’ä½“å®¡æ ¸æŠ¥å‘Š

**æŠ¥å‘Šç±»å‹**: {report_data["meta"]["time_range"]["description"]}  
**æ—¶é—´èŒƒå›´**: {report_data["meta"]["time_range"]["start_date"]} è‡³ {report_data["meta"]["time_range"]["end_date"]}  
**ç”Ÿæˆæ—¶é—´**: {report_data["meta"]["generated_at"]}

## ğŸ“Š æ±‡æ€»ä¿¡æ¯

- **æ—¶æœŸæ€»ç»“**: {report_data["summary"]["time_period_summary"]}
- **ä»»åŠ¡å®Œæˆç‡**: {report_data["summary"]["task_completion_rate"]}%
- **æ•´ä½“åˆè§„ç‡**: {report_data["summary"]["overall_compliance_rate"]}%
- **ä¸»è¦è¿è§„æ¥æº**: {report_data["summary"]["top_violation_source"]}
- **å¤å®¡å®Œæˆç‡**: {report_data["summary"]["review_completion_rate"]}%

## ğŸ¯ ä»»åŠ¡ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°é‡ |
|------|------|
| æ€»ä»»åŠ¡æ•° | {report_data["tasks"]["total"]} |
| è¿è¡Œä¸­ä»»åŠ¡ | {report_data["tasks"]["running"]} |
| éè¿è¡Œä¸­ä»»åŠ¡ | {report_data["tasks"]["non_running"]} |

### æŒ‰çŠ¶æ€åˆ†å¸ƒ
"""
    
    for status, count in report_data["tasks"]["by_status"].items():
        md_content += f"- **{status}**: {count}\n"
    
    md_content += f"""
## ğŸ“ æ–‡ä»¶ç»Ÿè®¡

**æ€»æ–‡ä»¶æ•°**: {report_data["files"]["total"]}

### æŒ‰ç±»å‹åˆ†å¸ƒ

| æ–‡ä»¶ç±»å‹ | æ•°é‡ | æ€»å¤§å°(MB) |
|----------|------|------------|
"""
    
    for file_type, stats in report_data["files"]["by_type"].items():
        md_content += f"| {file_type} | {stats['count']} | {stats['total_size_mb']} |\n"
    
    if "detailed_by_type" in report_data["files"]:
        md_content += "\n### è¯¦ç»†è¿è§„ç»Ÿè®¡\n\n"
        for file_type, stats in report_data["files"]["detailed_by_type"].items():
            md_content += f"**{file_type}**:\n"
            md_content += f"- æ€»æ•°: {stats['total']}\n"
            md_content += f"- åˆè§„: {stats['compliant']}\n"
            md_content += f"- ä¸åˆè§„: {stats['non_compliant']}\n\n"
    
    md_content += f"""
## âš ï¸ è¿è§„ç»Ÿè®¡

**æ€»æ£€æµ‹æ•°**: {report_data["violations"]["total_detections"]}

### æŒ‰ç»“æœåˆ†å¸ƒ

| ç»“æœç±»å‹ | æ•°é‡ | å¹³å‡ç½®ä¿¡åº¦ |
|----------|------|------------|
"""
    
    for result_type, stats in report_data["violations"]["by_result"].items():
        md_content += f"| {result_type} | {stats['count']} | {stats['avg_confidence']} |\n"
    
    md_content += f"""
### å¤å®¡çŠ¶æ€

- **å·²å¤å®¡**: {report_data["violations"]["review_status"]["reviewed"]}
- **å¾…å¤å®¡**: {report_data["violations"]["review_status"]["unreviewed"]}

---
*æŠ¥å‘Šç”±å¤šåª’ä½“å®¡æ ¸ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"å®¡æ ¸æŠ¥å‘Š_{timestamp}.md"
    
    return Response(
        content=md_content.encode('utf-8'),
        media_type="text/markdown",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

# æ‰©å±•åŠŸèƒ½ç±»
class ReportAnalyzer:
    """æŠ¥å‘Šæ™ºèƒ½åˆ†æå™¨"""
    
    @staticmethod
    def generate_insights(report_data: Dict, comparison_data: Dict = None) -> Dict:
        """ç”Ÿæˆæ™ºèƒ½åˆ†ææ´å¯Ÿ"""
        insights = {
            "performance_analysis": [],
            "risk_warnings": [],
            "recommendations": [],
            "efficiency_metrics": {}
        }
        
        # 1. æ€§èƒ½åˆ†æ
        task_completion_rate = report_data["summary"]["task_completion_rate"]
        compliance_rate = report_data["summary"]["overall_compliance_rate"]
        
        if task_completion_rate >= 95:
            insights["performance_analysis"].append("âœ… ä»»åŠ¡å®Œæˆç‡ä¼˜ç§€ï¼Œå·¥ä½œæµç¨‹é«˜æ•ˆ")
        elif task_completion_rate >= 80:
            insights["performance_analysis"].append("âš ï¸ ä»»åŠ¡å®Œæˆç‡è‰¯å¥½ï¼Œä»æœ‰æå‡ç©ºé—´")
        else:
            insights["performance_analysis"].append("âŒ ä»»åŠ¡å®Œæˆç‡åä½ï¼Œéœ€è¦ä¼˜åŒ–å¤„ç†æµç¨‹")
        
        if compliance_rate >= 90:
            insights["performance_analysis"].append("âœ… å†…å®¹åˆè§„ç‡ä¼˜ç§€ï¼Œå®¡æ ¸è´¨é‡é«˜")
        elif compliance_rate >= 75:
            insights["performance_analysis"].append("âš ï¸ å†…å®¹åˆè§„ç‡ä¸­ç­‰ï¼Œéœ€è¦åŠ å¼ºç›‘ç®¡")
        else:
            insights["performance_analysis"].append("âŒ å†…å®¹åˆè§„ç‡åä½ï¼Œå­˜åœ¨è¾ƒå¤šè¿è§„å†…å®¹")
        
        # 2. é£é™©é¢„è­¦
        violation_stats = report_data["violations"]["by_result"]
        non_compliant_count = violation_stats.get("ä¸åˆè§„", {}).get("count", 0)
        uncertain_count = violation_stats.get("ä¸ç¡®å®š", {}).get("count", 0)
        
        if non_compliant_count > 100:
            insights["risk_warnings"].append("ğŸš¨ é«˜é£é™©ï¼šè¿è§„å†…å®¹æ•°é‡å¼‚å¸¸ï¼Œå»ºè®®ç«‹å³æ’æŸ¥")
        
        if uncertain_count > 50:
            insights["risk_warnings"].append("âš ï¸ ä¸­é£é™©ï¼šå¤§é‡ä¸ç¡®å®šç»“æœéœ€è¦äººå·¥å¤å®¡")
        
        # æ£€æŸ¥å¤å®¡å®Œæˆç‡
        review_rate = report_data["summary"]["review_completion_rate"]
        if review_rate < 50:
            insights["risk_warnings"].append("â° å¤å®¡æ»åï¼šäººå·¥å¤å®¡è¿›åº¦ä¸¥é‡æ»å")
        
        # 3. æ”¹è¿›å»ºè®®
        insights["recommendations"].append("ğŸ“Š å®šæœŸåˆ†æè¿è§„è¶‹åŠ¿ï¼Œä¼˜åŒ–å®¡æ ¸ç­–ç•¥")
        insights["recommendations"].append("ğŸ¤– è€ƒè™‘è°ƒæ•´AIæ¨¡å‹å‚æ•°ï¼Œæé«˜æ£€æµ‹å‡†ç¡®æ€§")
        insights["recommendations"].append("ğŸ‘¥ å¢åŠ äººå·¥å¤å®¡äººå‘˜ï¼Œæé«˜å¤å®¡æ•ˆç‡")
        
        # 4. æ•ˆç‡æŒ‡æ ‡
        total_files = report_data["files"]["total"]
        total_tasks = report_data["tasks"]["total"]
        
        insights["efficiency_metrics"] = {
            "avg_files_per_task": round(total_files / total_tasks, 2) if total_tasks > 0 else 0,
            "processing_efficiency": "é«˜æ•ˆ" if task_completion_rate > 90 else "ä¸€èˆ¬",
            "quality_score": round((compliance_rate + review_rate) / 2, 1)
        }
        
        # 5. å¯¹æ¯”åˆ†æï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
        if comparison_data:
            insights["comparison"] = ReportAnalyzer._generate_comparison_insights(report_data, comparison_data)
        
        return insights
    
    @staticmethod
    def _generate_comparison_insights(current_data: Dict, previous_data: Dict) -> Dict:
        """ç”Ÿæˆå¯¹æ¯”åˆ†ææ´å¯Ÿ"""
        comparison = {}
        
        # ä»»åŠ¡æ•°é‡å¯¹æ¯”
        current_tasks = current_data["tasks"]["total"]
        previous_tasks = previous_data["tasks"]["total"]
        task_growth = ((current_tasks - previous_tasks) / previous_tasks * 100) if previous_tasks > 0 else 0
        
        # åˆè§„ç‡å¯¹æ¯”
        current_compliance = current_data["summary"]["overall_compliance_rate"]
        previous_compliance = previous_data["summary"]["overall_compliance_rate"]
        compliance_change = current_compliance - previous_compliance
        
        comparison["trends"] = {
            "task_growth_rate": round(task_growth, 2),
            "compliance_change": round(compliance_change, 2),
            "trend_direction": "ä¸Šå‡" if task_growth > 0 else "ä¸‹é™" if task_growth < 0 else "æŒå¹³"
        }
        
        # è¶‹åŠ¿è¯„ä»·
        if task_growth > 20:
            comparison["trend_analysis"] = "ğŸ“ˆ å¤„ç†é‡å¤§å¹…å¢é•¿ï¼Œå·¥ä½œè´Ÿè·å¢åŠ "
        elif task_growth > 0:
            comparison["trend_analysis"] = "ğŸ“Š å¤„ç†é‡ç¨³æ­¥å¢é•¿ï¼Œä¸šåŠ¡å‘å±•è‰¯å¥½"
        else:
            comparison["trend_analysis"] = "ğŸ“‰ å¤„ç†é‡æœ‰æ‰€ä¸‹é™ï¼Œéœ€è¦å…³æ³¨ä¸šåŠ¡å˜åŒ–"
        
        return comparison

class AlertManager:
    """é¢„è­¦ç®¡ç†å™¨"""
    
    @staticmethod
    def check_alerts(report_data: Dict) -> List[Dict]:
        """æ£€æŸ¥é¢„è­¦æ¡ä»¶"""
        alerts = []
        
        # 1. è¿è§„ç‡é¢„è­¦
        compliance_rate = report_data["summary"]["overall_compliance_rate"]
        if compliance_rate < 70:
            alerts.append({
                "level": "critical",
                "type": "compliance_rate",
                "message": f"åˆè§„ç‡è¿‡ä½ï¼š{compliance_rate}%ï¼Œä½äº70%é˜ˆå€¼",
                "action": "ç«‹å³æ£€æŸ¥å®¡æ ¸ç­–ç•¥å’Œå†…å®¹æ¥æº"
            })
        elif compliance_rate < 85:
            alerts.append({
                "level": "warning", 
                "type": "compliance_rate",
                "message": f"åˆè§„ç‡åä½ï¼š{compliance_rate}%ï¼Œéœ€è¦å…³æ³¨",
                "action": "åˆ†æä¸»è¦è¿è§„ç±»å‹ï¼Œä¼˜åŒ–å®¡æ ¸æµç¨‹"
            })
        
        # 2. å¤„ç†æ•ˆç‡é¢„è­¦
        task_completion_rate = report_data["summary"]["task_completion_rate"]
        if task_completion_rate < 80:
            alerts.append({
                "level": "warning",
                "type": "processing_efficiency", 
                "message": f"ä»»åŠ¡å®Œæˆç‡åä½ï¼š{task_completion_rate}%",
                "action": "æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½å’Œå¤„ç†ç“¶é¢ˆ"
            })
        
        # 3. å¤å®¡ç§¯å‹é¢„è­¦
        review_rate = report_data["summary"]["review_completion_rate"]
        if review_rate < 60:
            alerts.append({
                "level": "warning",
                "type": "review_backlog",
                "message": f"äººå·¥å¤å®¡è¿›åº¦æ»åï¼š{review_rate}%",
                "action": "å¢åŠ å¤å®¡äººå‘˜æˆ–ä¼˜åŒ–å¤å®¡æµç¨‹"
            })
        
        # 4. ç³»ç»Ÿå¼‚å¸¸é¢„è­¦
        running_tasks = report_data["tasks"]["running"]
        total_tasks = report_data["tasks"]["total"]
        if running_tasks > total_tasks * 0.3:
            alerts.append({
                "level": "info",
                "type": "system_load",
                "message": f"å½“å‰æœ‰{running_tasks}ä¸ªä»»åŠ¡åœ¨è¿è¡Œ",
                "action": "ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"
            })
        
        return alerts

class VisualizationGenerator:
    """å¯è§†åŒ–ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_charts_data(report_data: Dict) -> Dict:
        """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
        charts = {}
        
        # 1. æ–‡ä»¶ç±»å‹åˆ†å¸ƒé¥¼å›¾
        charts["file_type_distribution"] = {
            "type": "pie",
            "title": "æ–‡ä»¶ç±»å‹åˆ†å¸ƒ",
            "data": [
                {"name": file_type, "value": stats["count"]}
                for file_type, stats in report_data["files"]["by_type"].items()
            ]
        }
        
        # 2. è¿è§„ç»“æœåˆ†å¸ƒæŸ±çŠ¶å›¾
        charts["violation_distribution"] = {
            "type": "bar",
            "title": "è¿è§„æ£€æµ‹ç»“æœåˆ†å¸ƒ",
            "data": [
                {"name": result_type, "value": stats["count"]}
                for result_type, stats in report_data["violations"]["by_result"].items()
            ]
        }
        
        # 3. ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ
        charts["task_status_distribution"] = {
            "type": "doughnut",
            "title": "ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ",
            "data": [
                {"name": status, "value": count}
                for status, count in report_data["tasks"]["by_status"].items()
            ]
        }
        
        # 4. åˆè§„ç‡å¯¹æ¯”ï¼ˆå¦‚æœæœ‰è¯¦ç»†æ•°æ®ï¼‰
        if "detailed_by_type" in report_data["files"]:
            compliance_data = []
            for file_type, stats in report_data["files"]["detailed_by_type"].items():
                if stats["total"] > 0:
                    compliance_rate = (stats["compliant"] / stats["total"]) * 100
                    compliance_data.append({
                        "name": file_type,
                        "compliant": stats["compliant"],
                        "non_compliant": stats["non_compliant"],
                        "rate": round(compliance_rate, 2)
                    })
            
            charts["compliance_by_type"] = {
                "type": "grouped_bar",
                "title": "å„ç±»å‹æ–‡ä»¶åˆè§„æƒ…å†µ",
                "data": compliance_data
            }
        
        # 5. è¶‹åŠ¿å›¾ï¼ˆå¦‚æœæœ‰è¶‹åŠ¿æ•°æ®ï¼‰
        if report_data.get("trends"):
            charts["daily_trends"] = {
                "type": "line",
                "title": "æ¯æ—¥å¤„ç†è¶‹åŠ¿",
                "data": {
                    "tasks": report_data["trends"]["daily_tasks"],
                    "violations": report_data["trends"]["daily_violations"]
                }
            }
        
        return charts

# å¢å¼ºçš„æŠ¥å‘Šç”Ÿæˆæ¥å£
@router.post("/generate-enhanced", summary="ç”Ÿæˆå¢å¼ºæ™ºèƒ½æŠ¥å‘Š")
async def generate_enhanced_report(
    request: ReportRequest,
    include_comparison: bool = Query(False, description="æ˜¯å¦åŒ…å«åŒæœŸå¯¹æ¯”"),
    include_alerts: bool = Query(True, description="æ˜¯å¦åŒ…å«é¢„è­¦åˆ†æ"),
    include_insights: bool = Query(True, description="æ˜¯å¦åŒ…å«æ™ºèƒ½æ´å¯Ÿ"),
    include_charts: bool = Query(True, description="æ˜¯å¦åŒ…å«å›¾è¡¨æ•°æ®"),
    db: Session = Depends(get_db)
):
    """
    ç”Ÿæˆå¢å¼ºç‰ˆæ™ºèƒ½æŠ¥å‘Š
    
    åŒ…å«ä»¥ä¸‹æ‰©å±•åŠŸèƒ½ï¼š
    - ğŸ¤– **æ™ºèƒ½åˆ†æ**: AIè‡ªåŠ¨ç”Ÿæˆç»“è®ºå’Œå»ºè®®
    - ğŸ“Š **å¯¹æ¯”åˆ†æ**: ä¸å†å²åŒæœŸæ•°æ®å¯¹æ¯”
    - âš ï¸ **é¢„è­¦æœºåˆ¶**: å¼‚å¸¸æŒ‡æ ‡è‡ªåŠ¨å‘Šè­¦
    - ğŸ“ˆ **å¯è§†åŒ–æ•°æ®**: ç”Ÿæˆå›¾è¡¨æ•°æ®ç»“æ„
    """
    try:
        # è§£ææ—¶é—´èŒƒå›´
        start_date, end_date = _parse_time_range(request)
        
        # ç”ŸæˆåŸºç¡€æŠ¥å‘Šæ•°æ®
        report_data = _generate_report_data(db, start_date, end_date, request.creator_id, request.detailed)
        
        # è·å–å¯¹æ¯”æ•°æ®ï¼ˆåŒæœŸå¯¹æ¯”ï¼‰
        comparison_data = None
        if include_comparison:
            comparison_data = _get_comparison_data(db, start_date, end_date, request.creator_id)
        
        # æ™ºèƒ½åˆ†æ
        insights = None
        if include_insights:
            insights = ReportAnalyzer.generate_insights(report_data, comparison_data)
        
        # é¢„è­¦åˆ†æ
        alerts = None
        if include_alerts:
            alerts = AlertManager.check_alerts(report_data)
        
        # å›¾è¡¨æ•°æ®
        charts = None
        if include_charts:
            charts = VisualizationGenerator.generate_charts_data(report_data)
        
        # ç»„è£…å¢å¼ºæŠ¥å‘Š
        enhanced_report = {
            **report_data,
            "meta": {
                "report_type": request.report_type,
                "time_range": {
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "description": request.description or f"{request.report_type} æŠ¥å‘Š"
                },
                "generated_at": datetime.utcnow().isoformat(),
                "creator_id": request.creator_id,
                "enhanced_features": {
                    "comparison": include_comparison,
                    "alerts": include_alerts,
                    "insights": include_insights,
                    "charts": include_charts
                }
            },
            "insights": insights,
            "alerts": alerts,
            "charts": charts,
            "comparison": comparison_data
        }
        
        return APIResponse.success(
            data=enhanced_report,
            message="å¢å¼ºæŠ¥å‘Šç”ŸæˆæˆåŠŸ"
        )
    
    except Exception as e:
        logger.error(f"å¢å¼ºæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return APIResponse.error(
            message=f"å¢å¼ºæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
            code=500
        )

def _get_comparison_data(db: Session, current_start: datetime, current_end: datetime, creator_id: Optional[str]) -> Dict:
    """è·å–åŒæœŸå¯¹æ¯”æ•°æ®"""
    # è®¡ç®—å¯¹æ¯”æ—¶é—´æ®µï¼ˆä¸Šä¸€ä¸ªç›¸åŒé•¿åº¦çš„å‘¨æœŸï¼‰
    period_length = current_end - current_start
    comparison_start = current_start - period_length
    comparison_end = current_start
    
    # ç”Ÿæˆå¯¹æ¯”æœŸé—´çš„æŠ¥å‘Šæ•°æ®
    comparison_data = _generate_report_data(db, comparison_start, comparison_end, creator_id, detailed=False)
    
    # æ·»åŠ æ—¶é—´ä¿¡æ¯
    comparison_data["time_range"] = {
        "start_date": comparison_start.isoformat(),
        "end_date": comparison_end.isoformat(),
        "description": "å¯¹æ¯”æœŸé—´"
    }
    
    return comparison_data

# å®šæ—¶æŠ¥å‘Šç›¸å…³æ¥å£
class ScheduledReportRequest(BaseModel):
    """å®šæ—¶æŠ¥å‘Šè¯·æ±‚æ¨¡å‹"""
    name: str = Field(..., description="å®šæ—¶æŠ¥å‘Šåç§°")
    report_type: str = Field(..., description="æŠ¥å‘Šç±»å‹")
    schedule: str = Field(..., description="è°ƒåº¦è¡¨è¾¾å¼ (cronæ ¼å¼)")
    recipients: List[str] = Field(..., description="æ¥æ”¶äººé‚®ç®±åˆ—è¡¨")
    format: str = Field("markdown", description="æŠ¥å‘Šæ ¼å¼")
    enabled: bool = Field(True, description="æ˜¯å¦å¯ç”¨")
    creator_id: Optional[str] = Field(None, description="åˆ›å»ºè€…ID")

@router.post("/schedule", summary="åˆ›å»ºå®šæ—¶æŠ¥å‘Š")
async def create_scheduled_report(
    request: ScheduledReportRequest,
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºå®šæ—¶æŠ¥å‘Šä»»åŠ¡
    
    æ”¯æŒcronè¡¨è¾¾å¼ï¼š
    - `0 9 * * 1`: æ¯å‘¨ä¸€ä¸Šåˆ9ç‚¹ï¼ˆå‘¨æŠ¥ï¼‰
    - `0 9 1 * *`: æ¯æœˆ1å·ä¸Šåˆ9ç‚¹ï¼ˆæœˆæŠ¥ï¼‰
    - `0 9 1 1,4,7,10 *`: æ¯å­£åº¦ç¬¬ä¸€å¤©ä¸Šåˆ9ç‚¹ï¼ˆå­£æŠ¥ï¼‰
    - `0 9 1 1 *`: æ¯å¹´1æœˆ1å·ä¸Šåˆ9ç‚¹ï¼ˆå¹´æŠ¥ï¼‰
    """
    # è¿™é‡Œå¯ä»¥é›†æˆCelery Beatæˆ–å…¶ä»–å®šæ—¶ä»»åŠ¡ç³»ç»Ÿ
    # ç°åœ¨å…ˆè¿”å›æˆåŠŸå“åº”ï¼Œå®é™…å®ç°éœ€è¦é…ç½®å®šæ—¶ä»»åŠ¡
    
    schedule_info = {
        "id": f"scheduled_{datetime.utcnow().timestamp()}",
        "name": request.name,
        "report_type": request.report_type,
        "schedule": request.schedule,
        "recipients": request.recipients,
        "format": request.format,
        "enabled": request.enabled,
        "creator_id": request.creator_id,
        "created_at": datetime.utcnow().isoformat(),
        "next_run": "å¾…è®¡ç®—"  # å®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®cronè¡¨è¾¾å¼è®¡ç®—
    }
    
    return APIResponse.success(
        data=schedule_info,
        message="å®šæ—¶æŠ¥å‘Šåˆ›å»ºæˆåŠŸ"
    )

@router.get("/alerts/dashboard", summary="è·å–é¢„è­¦ä»ªè¡¨æ¿")
async def get_alerts_dashboard(
    days: int = Query(7, ge=1, le=90, description="æŸ¥è¯¢å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–é¢„è­¦ä»ªè¡¨æ¿æ•°æ®
    
    æ˜¾ç¤ºæœ€è¿‘Nå¤©çš„å…³é”®æŒ‡æ ‡å’Œé¢„è­¦ä¿¡æ¯
    """
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=days)
    
    # ç”Ÿæˆè¿‘æœŸæ•°æ®
    recent_data = _generate_report_data(db, start_date, end_date, None, detailed=True)
    
    # æ£€æŸ¥é¢„è­¦
    alerts = AlertManager.check_alerts(recent_data)
    
    # å…³é”®æŒ‡æ ‡
    key_metrics = {
        "total_tasks": recent_data["tasks"]["total"],
        "running_tasks": recent_data["tasks"]["running"],
        "compliance_rate": recent_data["summary"]["overall_compliance_rate"],
        "review_completion_rate": recent_data["summary"]["review_completion_rate"],
        "alert_count": len(alerts),
        "critical_alerts": len([a for a in alerts if a["level"] == "critical"])
    }
    
    return APIResponse.success(
        data={
            "key_metrics": key_metrics,
            "alerts": alerts,
            "time_range": f"æœ€è¿‘{days}å¤©",
            "last_updated": datetime.utcnow().isoformat()
        },
        message="é¢„è­¦ä»ªè¡¨æ¿æ•°æ®è·å–æˆåŠŸ"
    )

@router.get("/templates", summary="è·å–æŠ¥å‘Šæ¨¡æ¿")
async def get_report_templates():
    """è·å–é¢„å®šä¹‰çš„æŠ¥å‘Šæ¨¡æ¿"""
    templates = [
        {
            "name": "æ™ºèƒ½å‘¨æŠ¥æ¨¡æ¿",
            "type": "weekly", 
            "description": "AIæ™ºèƒ½åˆ†æçš„å‘¨æŠ¥ï¼ŒåŒ…å«æ€§èƒ½æ´å¯Ÿå’Œæ”¹è¿›å»ºè®®",
            "features": ["æ™ºèƒ½åˆ†æ", "å¯¹æ¯”è¶‹åŠ¿", "é¢„è­¦æé†’"],
            "example": "æœ¬å‘¨å¤„ç†æ•ˆç‡æå‡15%ï¼Œå»ºè®®ä¼˜åŒ–è§†é¢‘å®¡æ ¸ç­–ç•¥"
        },
        {
            "name": "ç®¡ç†æœˆæŠ¥æ¨¡æ¿",
            "type": "monthly",
            "description": "ç®¡ç†å±‚æœˆåº¦æŠ¥å‘Šï¼ŒåŒ…å«è¯¦ç»†æ•°æ®åˆ†æå’Œå†³ç­–å»ºè®®",
            "features": ["å…¨é¢ç»Ÿè®¡", "è¶‹åŠ¿åˆ†æ", "é£é™©è¯„ä¼°", "å¯è§†åŒ–å›¾è¡¨"],
            "example": "æœˆåº¦åˆè§„ç‡è¾¾95%ï¼ŒåŒæ¯”æå‡8%ï¼Œå»ºè®®æ‰©å¤§å®¡æ ¸å›¢é˜Ÿ"
        },
        {
            "name": "è´¨é‡å­£æŠ¥æ¨¡æ¿", 
            "type": "quarterly",
            "description": "è´¨é‡ç®¡ç†å­£åº¦æŠ¥å‘Šï¼Œé‡ç‚¹å…³æ³¨åˆè§„æ€§å’Œæ”¹è¿›æªæ–½",
            "features": ["è´¨é‡æŒ‡æ ‡", "å¯¹æ¯”åˆ†æ", "æ”¹è¿›è®¡åˆ’"],
            "example": "Q3è´¨é‡æŒ‡æ ‡å…¨é¢è¾¾æ ‡ï¼Œåˆ¶å®šQ4ä¼˜åŒ–ç­–ç•¥"
        },
        {
            "name": "å¹´åº¦æ€»ç»“æ¨¡æ¿",
            "type": "yearly", 
            "description": "å¹´åº¦å…¨é¢æ€»ç»“ï¼ŒåŒ…å«æˆå°±å›é¡¾å’Œæ¥å¹´è§„åˆ’",
            "features": ["å¹´åº¦å›é¡¾", "æˆå°±å±•ç¤º", "å‘å±•è§„åˆ’"],
            "example": "å…¨å¹´å®¡æ ¸1000ä¸‡æ–‡ä»¶ï¼Œå»ºç«‹è¡Œä¸šé¢†å…ˆçš„AIå®¡æ ¸ä½“ç³»"
        }
    ]
    
    return APIResponse.success(
        data=templates,
        message="æŠ¥å‘Šæ¨¡æ¿è·å–æˆåŠŸ"
    )


@router.post("/export/enhanced", summary="å¯¼å‡ºå¢å¼ºæŠ¥å‘Š")
async def export_enhanced_report(
    request: ReportRequest,
    export_format: str = Query("pdf", regex="^(pdf|excel|html|json)$", description="å¯¼å‡ºæ ¼å¼"),
    include_charts: bool = Query(True, description="æ˜¯å¦åŒ…å«å›¾è¡¨"),
    include_insights: bool = Query(True, description="æ˜¯å¦åŒ…å«æ™ºèƒ½åˆ†æ"),
    db: Session = Depends(get_db)
):
    """
    å¯¼å‡ºå¢å¼ºç‰ˆæŠ¥å‘Šï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    æ”¯æŒæ ¼å¼ï¼š
    - **pdf**: PDFæŠ¥å‘Šï¼ˆåŒ…å«å›¾è¡¨ï¼‰
    - **excel**: Excelå·¥ä½œç°¿ï¼ˆå¤šsheetï¼‰
    - **html**: äº¤äº’å¼HTMLæŠ¥å‘Š
    - **json**: å®Œæ•´JSONæ•°æ®
    """
    try:
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šæ•°æ®
        start_date, end_date = _parse_time_range(request)
        report_data = _generate_report_data(db, start_date, end_date, request.creator_id, True)
        
        # æ·»åŠ æ‰©å±•æ•°æ®
        if include_insights:
            report_data["insights"] = ReportAnalyzer.generate_insights(report_data)
        
        if include_charts:
            report_data["charts"] = VisualizationGenerator.generate_charts_data(report_data)
        
        report_data["alerts"] = AlertManager.check_alerts(report_data)
        
        # æ ¹æ®æ ¼å¼å¯¼å‡º
        if export_format == "excel":
            return _export_excel_report(report_data)
        elif export_format == "html":
            return _export_html_report(report_data)
        elif export_format == "pdf":
            return _export_pdf_report(report_data)
        else:  # json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"enhanced_report_{timestamp}.json"
            
            return Response(
                content=json.dumps(report_data, ensure_ascii=False, indent=2).encode('utf-8'),
                media_type="application/json",
                headers={"Content-Disposition": f"attachment; filename={filename}"}
            )
    
    except Exception as e:
        logger.error(f"å¢å¼ºæŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {e}")
        return APIResponse.error(f"æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {str(e)}", 500)

def _export_excel_report(report_data: Dict) -> Response:
    """å¯¼å‡ºExcelæ ¼å¼æŠ¥å‘Š"""
    from io import BytesIO
    import pandas as pd
    
    output = BytesIO()
    
    # åˆ›å»ºExcelå†™å…¥å™¨
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        
        # Sheet 1: æŠ¥å‘Šæ‘˜è¦
        summary_data = [
            ["æŒ‡æ ‡", "æ•°å€¼"],
            ["æ€»ä»»åŠ¡æ•°", report_data["tasks"]["total"]],
            ["è¿è¡Œä¸­ä»»åŠ¡", report_data["tasks"]["running"]],
            ["æ€»æ–‡ä»¶æ•°", report_data["files"]["total"]],
            ["æ•´ä½“åˆè§„ç‡", f"{report_data['summary']['overall_compliance_rate']:.2f}%"],
            ["ä»»åŠ¡å®Œæˆç‡", f"{report_data['summary']['task_completion_rate']:.2f}%"],
            ["å¤å®¡å®Œæˆç‡", f"{report_data['summary']['review_completion_rate']:.2f}%"]
        ]
        
        summary_df = pd.DataFrame(summary_data[1:], columns=summary_data[0])
        summary_df.to_excel(writer, sheet_name='æŠ¥å‘Šæ‘˜è¦', index=False)
        
        # Sheet 2: æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        file_type_data = []
        for file_type, stats in report_data["files"]["by_type"].items():
            file_type_data.append([file_type, stats["count"], stats["total_size_mb"]])
        
        if file_type_data:
            file_df = pd.DataFrame(file_type_data, columns=["æ–‡ä»¶ç±»å‹", "æ•°é‡", "æ€»å¤§å°(MB)"])
            file_df.to_excel(writer, sheet_name='æ–‡ä»¶ç»Ÿè®¡', index=False)
        
        # Sheet 3: è¿è§„ç»Ÿè®¡
        violation_data = []
        for result_type, stats in report_data["violations"]["by_result"].items():
            violation_data.append([result_type, stats["count"], f"{stats['avg_confidence']:.3f}"])
        
        if violation_data:
            violation_df = pd.DataFrame(violation_data, columns=["ç»“æœç±»å‹", "æ•°é‡", "å¹³å‡ç½®ä¿¡åº¦"])
            violation_df.to_excel(writer, sheet_name='è¿è§„ç»Ÿè®¡', index=False)
        
        # Sheet 4: æ™ºèƒ½æ´å¯Ÿï¼ˆå¦‚æœæœ‰ï¼‰
        if "insights" in report_data and report_data["insights"]:
            insights_data = []
            for analysis in report_data["insights"]["performance_analysis"]:
                insights_data.append(["æ€§èƒ½åˆ†æ", analysis])
            for warning in report_data["insights"]["risk_warnings"]:
                insights_data.append(["é£é™©é¢„è­¦", warning])
            for recommendation in report_data["insights"]["recommendations"]:
                insights_data.append(["æ”¹è¿›å»ºè®®", recommendation])
            
            if insights_data:
                insights_df = pd.DataFrame(insights_data, columns=["ç±»å‹", "å†…å®¹"])
                insights_df.to_excel(writer, sheet_name='æ™ºèƒ½åˆ†æ', index=False)
        
        # Sheet 5: é¢„è­¦ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if "alerts" in report_data and report_data["alerts"]:
            alerts_data = []
            for alert in report_data["alerts"]:
                alerts_data.append([alert["level"], alert["type"], alert["message"], alert["action"]])
            
            if alerts_data:
                alerts_df = pd.DataFrame(alerts_data, columns=["çº§åˆ«", "ç±»å‹", "æ¶ˆæ¯", "å»ºè®®æªæ–½"])
                alerts_df.to_excel(writer, sheet_name='é¢„è­¦ä¿¡æ¯', index=False)
    
    output.seek(0)
    content = output.getvalue()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"enhanced_report_{timestamp}.xlsx"
    
    return Response(
        content=content,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

def _export_html_report(report_data: Dict) -> Response:
    """å¯¼å‡ºäº¤äº’å¼HTMLæŠ¥å‘Š"""
    
    # ç”Ÿæˆå›¾è¡¨çš„JavaScriptä»£ç 
    charts_js = ""
    if "charts" in report_data and report_data["charts"]:
        for chart_id, chart_data in report_data["charts"].items():
            if chart_data["type"] == "pie":
                charts_js += f"""
                var {chart_id}_data = {json.dumps(chart_data["data"])};
                var {chart_id}_ctx = document.getElementById('{chart_id}').getContext('2d');
                new Chart({chart_id}_ctx, {{
                    type: 'pie',
                    data: {{
                        labels: {chart_id}_data.map(item => item.name),
                        datasets: [{{
                            data: {chart_id}_data.map(item => item.value),
                            backgroundColor: ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0', '#9966FF']
                        }}]
                    }},
                    options: {{
                        responsive: true,
                        plugins: {{
                            title: {{ display: true, text: '{chart_data["title"]}' }}
                        }}
                    }}
                }});
                """
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>å¤šåª’ä½“å®¡æ ¸æŠ¥å‘Š</title>
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <style>
            body {{ font-family: 'Microsoft YaHei', sans-serif; margin: 20px; background: #f5f5f5; }}
            .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .header {{ text-align: center; border-bottom: 3px solid #007bff; padding-bottom: 20px; margin-bottom: 30px; }}
            .metric-card {{ display: inline-block; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; margin: 10px; border-radius: 10px; min-width: 150px; text-align: center; }}
            .metric-value {{ font-size: 2em; font-weight: bold; }}
            .metric-label {{ font-size: 0.9em; opacity: 0.9; }}
            .section {{ margin: 30px 0; }}
            .section-title {{ font-size: 1.5em; color: #333; border-left: 4px solid #007bff; padding-left: 15px; margin-bottom: 20px; }}
            .chart-container {{ width: 48%; display: inline-block; margin: 1%; }}
            .alert {{ padding: 15px; margin: 10px 0; border-radius: 5px; }}
            .alert-critical {{ background: #ffebee; border-left: 4px solid #f44336; }}
            .alert-warning {{ background: #fff3e0; border-left: 4px solid #ff9800; }}
            .alert-info {{ background: #e3f2fd; border-left: 4px solid #2196f3; }}
            .insight {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #28a745; }}
            table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
            th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
            th {{ background: #007bff; color: white; }}
            tr:nth-child(even) {{ background: #f2f2f2; }}
            .footer {{ text-align: center; margin-top: 40px; color: #666; font-size: 0.9em; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ“Š å¤šåª’ä½“å®¡æ ¸æŠ¥å‘Š</h1>
                <p>æŠ¥å‘Šç±»å‹: {report_data.get("meta", {}).get("time_range", {}).get("description", "æœªçŸ¥")}</p>
                <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <!-- å…³é”®æŒ‡æ ‡å¡ç‰‡ -->
            <div class="section">
                <div class="metric-card">
                    <div class="metric-value">{report_data["tasks"]["total"]}</div>
                    <div class="metric-label">æ€»ä»»åŠ¡æ•°</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{report_data["files"]["total"]}</div>
                    <div class="metric-label">æ€»æ–‡ä»¶æ•°</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{report_data["summary"]["overall_compliance_rate"]:.1f}%</div>
                    <div class="metric-label">åˆè§„ç‡</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{report_data["tasks"]["running"]}</div>
                    <div class="metric-label">è¿è¡Œä¸­ä»»åŠ¡</div>
                </div>
            </div>
            
            <!-- å›¾è¡¨åŒºåŸŸ -->
            {_generate_charts_html(report_data.get("charts", {}))}
            
            <!-- ç»Ÿè®¡è¡¨æ ¼ -->
            <div class="section">
                <h2 class="section-title">ğŸ“ æ–‡ä»¶ç±»å‹ç»Ÿè®¡</h2>
                <table>
                    <thead>
                        <tr><th>æ–‡ä»¶ç±»å‹</th><th>æ•°é‡</th><th>æ€»å¤§å°(MB)</th><th>å æ¯”</th></tr>
                    </thead>
                    <tbody>
                        {_generate_file_stats_table(report_data["files"]["by_type"], report_data["files"]["total"])}
                    </tbody>
                </table>
            </div>
            
            <div class="section">
                <h2 class="section-title">âš ï¸ è¿è§„ç»Ÿè®¡</h2>
                <table>
                    <thead>
                        <tr><th>ç»“æœç±»å‹</th><th>æ•°é‡</th><th>å¹³å‡ç½®ä¿¡åº¦</th><th>å æ¯”</th></tr>
                    </thead>
                    <tbody>
                        {_generate_violation_stats_table(report_data["violations"]["by_result"], report_data["violations"]["total_detections"])}
                    </tbody>
                </table>
            </div>
            
            <!-- æ™ºèƒ½æ´å¯Ÿ -->
            {_generate_insights_html(report_data.get("insights", {}))}
            
            <!-- é¢„è­¦ä¿¡æ¯ -->
            {_generate_alerts_html(report_data.get("alerts", []))}
            
            <div class="footer">
                <p>ğŸ¤– æ­¤æŠ¥å‘Šç”±å¤šåª’ä½“å®¡æ ¸ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ | ğŸ“§ å¦‚æœ‰ç–‘é—®è¯·è”ç³»æŠ€æœ¯æ”¯æŒ</p>
            </div>
        </div>
        
        <script>
            {charts_js}
        </script>
    </body>
    </html>"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"interactive_report_{timestamp}.html"
    
    return Response(
        content=html_content.encode('utf-8'),
        media_type="text/html",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

def _generate_charts_html(charts_data: Dict) -> str:
    """ç”Ÿæˆå›¾è¡¨HTML"""
    if not charts_data:
        return ""
    
    charts_html = '<div class="section"><h2 class="section-title">ğŸ“ˆ æ•°æ®å¯è§†åŒ–</h2>'
    
    for chart_id, chart_info in charts_data.items():
        charts_html += f'''
        <div class="chart-container">
            <canvas id="{chart_id}" width="400" height="300"></canvas>
        </div>
        '''
    
    charts_html += '</div>'
    return charts_html

def _generate_file_stats_table(file_stats: Dict, total_files: int) -> str:
    """ç”Ÿæˆæ–‡ä»¶ç»Ÿè®¡è¡¨æ ¼"""
    rows = ""
    for file_type, stats in file_stats.items():
        percentage = (stats["count"] / total_files * 100) if total_files > 0 else 0
        rows += f"""
        <tr>
            <td>{file_type}</td>
            <td>{stats["count"]}</td>
            <td>{stats["total_size_mb"]}</td>
            <td>{percentage:.1f}%</td>
        </tr>
        """
    return rows

def _generate_violation_stats_table(violation_stats: Dict, total_detections: int) -> str:
    """ç”Ÿæˆè¿è§„ç»Ÿè®¡è¡¨æ ¼"""
    rows = ""
    for result_type, stats in violation_stats.items():
        percentage = (stats["count"] / total_detections * 100) if total_detections > 0 else 0
        rows += f"""
        <tr>
            <td>{result_type}</td>
            <td>{stats["count"]}</td>
            <td>{stats["avg_confidence"]:.3f}</td>
            <td>{percentage:.1f}%</td>
        </tr>
        """
    return rows

def _generate_insights_html(insights: Dict) -> str:
    """ç”Ÿæˆæ™ºèƒ½æ´å¯ŸHTML"""
    if not insights:
        return ""
    
    html = '<div class="section"><h2 class="section-title">ğŸ¤– æ™ºèƒ½æ´å¯Ÿ</h2>'
    
    # æ€§èƒ½åˆ†æ
    if insights.get("performance_analysis"):
        html += '<h3>ğŸ“Š æ€§èƒ½åˆ†æ</h3>'
        for analysis in insights["performance_analysis"]:
            html += f'<div class="insight">{analysis}</div>'
    
    # é£é™©é¢„è­¦
    if insights.get("risk_warnings"):
        html += '<h3>âš ï¸ é£é™©é¢„è­¦</h3>'
        for warning in insights["risk_warnings"]:
            html += f'<div class="insight" style="border-left-color: #ff9800;">{warning}</div>'
    
    # æ”¹è¿›å»ºè®®
    if insights.get("recommendations"):
        html += '<h3>ğŸ’¡ æ”¹è¿›å»ºè®®</h3>'
        for recommendation in insights["recommendations"]:
            html += f'<div class="insight" style="border-left-color: #2196f3;">{recommendation}</div>'
    
    html += '</div>'
    return html

def _generate_alerts_html(alerts: List[Dict]) -> str:
    """ç”Ÿæˆé¢„è­¦ä¿¡æ¯HTML"""
    if not alerts:
        return ""
    
    html = '<div class="section"><h2 class="section-title">ğŸš¨ é¢„è­¦ä¿¡æ¯</h2>'
    
    for alert in alerts:
        alert_class = f"alert-{alert['level']}"
        level_icon = {"critical": "ğŸš¨", "warning": "âš ï¸", "info": "â„¹ï¸"}.get(alert['level'], "â„¹ï¸")
        
        html += f'''
        <div class="alert {alert_class}">
            <strong>{level_icon} {alert['type'].upper()}</strong><br>
            {alert['message']}<br>
            <small><strong>å»ºè®®æªæ–½:</strong> {alert['action']}</small>
        </div>
        '''
    
    html += '</div>'
    return html

def _export_pdf_report(report_data: Dict) -> Response:
    """å¯¼å‡ºPDFæ ¼å¼æŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # è¿™é‡Œå¯ä»¥é›†æˆ weasyprintã€reportlab ç­‰PDFç”Ÿæˆåº“
    # ç°åœ¨å…ˆè¿”å›HTMLè½¬PDFçš„æç¤º
    
    pdf_content = f"""
    PDFæŠ¥å‘ŠåŠŸèƒ½éœ€è¦å®‰è£…é¢å¤–ä¾èµ–ï¼š
    pip install weasyprint
    æˆ–
    pip install reportlab
    
    å½“å‰è¿”å›æ–‡æœ¬æ ¼å¼æŠ¥å‘Šï¼š
    
    ===============================
    å¤šåª’ä½“å®¡æ ¸æŠ¥å‘Š
    ===============================
    
    ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    
    ğŸ“Š å…³é”®æŒ‡æ ‡
    - æ€»ä»»åŠ¡æ•°: {report_data["tasks"]["total"]}
    - è¿è¡Œä¸­ä»»åŠ¡: {report_data["tasks"]["running"]}
    - æ€»æ–‡ä»¶æ•°: {report_data["files"]["total"]}
    - åˆè§„ç‡: {report_data["summary"]["overall_compliance_rate"]:.2f}%
    
    ğŸ“ æ–‡ä»¶ç»Ÿè®¡
    {json.dumps(report_data["files"]["by_type"], ensure_ascii=False, indent=2)}
    
    âš ï¸ è¿è§„ç»Ÿè®¡
    {json.dumps(report_data["violations"]["by_result"], ensure_ascii=False, indent=2)}
    
    ===============================
    """
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"report_{timestamp}.txt"
    
    return Response(
        content=pdf_content.encode('utf-8'),
        media_type="text/plain",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

# å®æ—¶ç›‘æ§æ¥å£
@router.get("/monitor/realtime", summary="å®æ—¶ç›‘æ§æ•°æ®")
async def get_realtime_monitor(
    db: Session = Depends(get_db)
):
    """
    è·å–å®æ—¶ç›‘æ§æ•°æ®
    ç”¨äºä»ªè¡¨æ¿å®æ—¶åˆ·æ–°
    """
    now = datetime.utcnow()
    
    # æœ€è¿‘1å°æ—¶æ•°æ®
    hour_ago = now - timedelta(hours=1)
    
    # å®æ—¶æŒ‡æ ‡
    running_tasks = db.query(ReviewTask).filter(
        ReviewTask.status == TaskStatus.PROCESSING
    ).count()
    
    recent_violations = db.query(ReviewResult).filter(
        ReviewResult.created_at >= hour_ago,
        ReviewResult.violation_result == ViolationResult.NON_COMPLIANT
    ).count()
    
    processing_files = db.query(ReviewFile).filter(
        ReviewFile.status == FileStatus.PROCESSING
    ).count()
    
    pending_review = db.query(ReviewResult).filter(
        ReviewResult.is_reviewed == False,
        ReviewResult.violation_result == ViolationResult.NON_COMPLIANT
    ).count()
    
    # ç³»ç»ŸçŠ¶æ€
    system_status = "æ­£å¸¸"
    if running_tasks > 50:
        system_status = "é«˜è´Ÿè½½"
    elif recent_violations > 100:
        system_status = "é«˜é£é™©"
    
    return APIResponse.success(
        data={
            "timestamp": now.isoformat(),
            "realtime_metrics": {
                "running_tasks": running_tasks,
                "processing_files": processing_files,
                "recent_violations": recent_violations,
                "pending_review": pending_review,
                "system_status": system_status
            },
            "performance": {
                "avg_processing_time": "2.3ç§’/æ–‡ä»¶",  # å¯ä»¥ä»å®é™…æ•°æ®è®¡ç®—
                "success_rate": "98.5%",
                "queue_depth": processing_files
            }
        },
        message="å®æ—¶ç›‘æ§æ•°æ®è·å–æˆåŠŸ"
    )